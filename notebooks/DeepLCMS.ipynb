{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ecb309f7",
   "metadata": {},
   "source": [
    "---\n",
    "title: 'DeepLCMS: Leveraging transfer learning for the classification of pseudo images in mass spectrometry-based analysis'\n",
    "author: Adam Cseresznye\n",
    "date: '2023-19-12'\n",
    "bibliography: DeepLCMS.bib\n",
    "categories:\n",
    "  - DeepLCMS\n",
    "jupyter: python3\n",
    "toc: true\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5a692-e95d-4785-8d85-ed1cc10b4056",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Representative examples of DeepLCMS predictions accompanied by their corresponding probability estimates.](exp-5-prediction_matrix.png){fig-align=\"center\" width=50%}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955da8b-ac66-47c9-95ba-2c66f68fe821",
   "metadata": {},
   "source": [
    "Welcome to DeepLCMS, a project that combines mass spectrometry analysis with the power of deep learning models!\n",
    "\n",
    "Unlike traditional methods, DeepLCMS eliminates the need for extensive data processing, including peak alignment, data annotation, quantitation, and other time-consuming steps. Instead, it relies on the power of deep learning to directly classify mass spectrometry-based pseudo-images with high accuracy. To demonstrate the capabilities of pre-trained neural networks for high-resolution LC/MS data, we successfully apply our convolutional neural network (CNN) to categorize substance abuse cases. We utilize the openly available Golestan Cohort Study's metabolomics HRMS/LC data to train and evaluate our CNN [@pourshams_cohort_2010; @ghanbari_metabolomics_2021; @li_untargeted_2020]. We also delve into the network's decision-making process through TorchCam library. This tool allows us to gain insights into the factors that influence the network's classifications, helping us identify key compound classes that play a crucial role in differentiating between classes. By analyzing retention time and molecular weight, we can pinpoint areas of interest within the data.\n",
    "\n",
    "DeepLCMS paves the way for a new era of mass spectrometry analysis, offering a faster, more efficient, and more insightful approach to data interpretation. Its ability to directly classify pseudo-images without extensive preprocessing opens up a world of possibilities for researchers and clinicians alike."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4698f-d15a-4484-a3ff-692eb1e0685b",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "**At a glance**\n",
    "\n",
    "The DeepLCMS project aims to provide researchers with a reproducible source code for leveraging deep learning for mass spectrometry data analysis. It distinguishes itself from previous studies by:\n",
    "* Comparing Diverse Architecture Families: Assessing a broader range of architecture families to find the most suitable one, including cutting-edge architectures like vision transformers.\n",
    "* Hyperparameter Tuning: Conducting basic hyperparameter tuning to optimize the learning rate using Optuna including optimizer, and learning rate scheduler – crucial aspects beyond the architecture itself.\n",
    "* Image Quality Analysis: Investigating the impact of image quality on validation metrics, examining image sharpness and data augmentation imitating retention time shift.\n",
    "* Regularization Techniques: Employing regularization techniques like random-tilting images and random erasing during training to improve model generalization.\n",
    "* Interpreting Pretrained Network Decisions: Analyzing how the pre-trained network makes its decisions using TorchVision.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af189aa",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821aab42-6ea3-4277-9c47-01586fc1b53f",
   "metadata": {},
   "source": [
    "While computer vision has gained widespread adoption in various aspects of our lives[@dobson_birth_2023], its application in medical imaging and biosciences has lagged behind, primarily due to limitations in clinical dataset size, accessibility, privacy concerns, experimental complexity, and high acquisition costs. For such applications, transfer learning has emerged as a potential solution[@seddiki_towards_2020]. This technique is particularly effective with small datasets, requiring fewer computational resources while achieving good classification accuracy compared to models trained from scratch. Transfer learning involves a two-step process. Initially, a robust data representation is learned by training a model on a dataset comprising a vast amount of annotated data encompassing numerous categories (ImageNet for example). This representation is then utilized to construct a new model based on a smaller annotated dataset containing fewer categories. \n",
    "\n",
    "## Application of Pretrained Neural Networks for Mass Spectrometry Data\n",
    "\n",
    "The use of pre-trained neural networks for mass spectrometry data analysis is relatively new, with only a handful of publications available to date. These studies have demonstrated the potential of deep learning models to extract meaningful information from raw mass spectrometry data and perform predictive tasks without the need for extensive data processing as required by the traditional workflows.\n",
    "\n",
    "## Previous Research\n",
    "\n",
    "* In 2018, @behrmann_deep_2018 used deep learning techniques for tumor classification in Imaging Mass Spectrometry (IMS) data.\n",
    "\n",
    "* In 2020, @seddiki_towards_2020 utilized MALDI-TOF images of rat brain samples to assess the ability of three different CNN architectures – LeNet, Lecun, and VGG9 – to differentiate between different types of cancers based on their molecular profiles.\n",
    "\n",
    "* In 2021, @cadow_feasibility_2021 explored the use of pre-trained networks for the classification of tumors from normal prostate biopsies derived from SWATH-MS data. They delved into the potential of deep learning models for analyzing raw mass spectrometry data and performing predictive tasks without the need for protein quantification. To process raw MS images, the authors employed pre-trained neural network models to convert them into numerical vectors, enabling further processing. They then compared several classifiers, including logistic regression, support vector machines, and random forests, to accurately predict the phenotype.\n",
    "\n",
    "* In 2022, @shen_deep_2022 released deepPseudoMSI, a deep learning-based pseudo-mass spectrometry imaging platform, designed to predict the gestational age in pregnant women based on LC-MS-based metabolomics data. This application consists of two components: Pseudo-MS Image Converter: for converting LC-MS data into pseudo-images and the deep learning model itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e76a6e-4270-4af3-adbf-2294b5d81ce1",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "## Project Structure\n",
    "\n",
    "To accommodate the high computational demands of neural network training, the DeepLCMS project is divided into two main parts. The first part focuses on data preprocessing, specifically converting LC/MS data into pseudo-images using the PyOpenMS library, which is written in C++ and optimized for efficiency. This task can be handled on a CPU, and the corresponding source code is found in the `src/deeplcms_functions` directory.\n",
    "\n",
    "To effectively train the neural networks that demand GPU acceleration, the project employs the PyTorch Lightning framework, a comprehensive solution for building and deploying deep learning models. Training experiments are conducted within Jupyter Notebooks hosted on Google Colab, a cloud platform equipped with free GPU access. The training code and corresponding modules reside within the `src/train_google_colab` directory. This folder seamlessly integrates with Google Colab, allowing for effortless module imports.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dc28ea-df1c-4007-bf52-327b8a7ec8e1",
   "metadata": {},
   "source": [
    "![Proposed conditions for evaluating selected image characteristics as hyperparameters.](experimental_plan.jpg){#fig-1 fig-align=\"center\" width=50%}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09821cba-07d0-4a9a-81ee-ac2c1fc6d820",
   "metadata": {},
   "source": [
    "# Materials and Methods\n",
    "# Dataset\n",
    "\n",
    "To ensure the feasibility of our proof-of-concept demonstration, we carefully selected a suitable dataset from the Metabolomics Workbench. We prioritized studies with at least two distinct groups and a sample size of at least 200. Additionally, we selected a dataset with a disk requirement of less than 50 GB to minimize computational resources needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ade18-4cc3-4eca-aa38-48f089a609e1",
   "metadata": {},
   "source": [
    "# Results and Discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c502a-e3d7-4d16-9683-acc3d849247c",
   "metadata": {},
   "source": [
    "# Get in touch\n",
    "\n",
    "Did the app help with your research? Any ideas for making it better? Get in touch! I would love to hear from you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a7090-8354-495f-b068-23ae990fcb19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
