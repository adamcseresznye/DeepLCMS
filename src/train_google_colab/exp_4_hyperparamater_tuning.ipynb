{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15739,
     "status": "ok",
     "timestamp": 1701718040998,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "S9vhq3fcEHwj",
    "outputId": "ea55af85-5c46-4c5c-a7a4-8b7fd3fd26f5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B10ISUtcE4nE"
   },
   "source": [
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 41024,
     "status": "ok",
     "timestamp": 1701718082017,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "EaleshIpENkS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install scikit-posthocs\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701718106074,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "eQbyJQmAXznU"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from typing import Optional, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import train_NN\n",
    "from google.colab import drive\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import Callback, EarlyStopping\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from timm import create_model\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAUROC,\n",
    "    BinaryF1Score,\n",
    "    BinaryPrecision,\n",
    "    BinaryRecall,\n",
    ")\n",
    "\n",
    "import optuna\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall\n",
    "\n",
    "\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1701718108761,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1701718217491,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "!unzip -q \"*.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1701718232914,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "Jh0cGdllMv8h",
    "outputId": "4d39e676-7815-4402-cd0a-dbc13dff1349"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWU7V2tIBhAl"
   },
   "source": [
    "# Getting a tunable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1701718240552,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "QDdrLD2CBaWu"
   },
   "outputs": [],
   "source": [
    "class Resnet_model(pl.LightningModule):\n",
    "    def __init__(self, hyperparameters):\n",
    "        super().__init__()\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.model = create_model(\"resnet50d.a3_in1k\", pretrained=True, num_classes=1)\n",
    "\n",
    "        # Freeze all layers except for the last one\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=512, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.hyperparameters[\"dropout\"]),\n",
    "            nn.Linear(in_features=512, out_features=256, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        self.log(\n",
    "            \"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=False, logger=True\n",
    "        )\n",
    "        # Calculate F1\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=False, logger=True\n",
    "        )\n",
    "        # Calculate Precision\n",
    "        metric_precision = BinaryPrecision().to(y.device)\n",
    "        precision = metric_precision(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_precision\",\n",
    "            precision,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=False,\n",
    "            logger=True,\n",
    "        )\n",
    "        # Calculate Recall\n",
    "        metric_f1 = BinaryRecall().to(y.device)\n",
    "        recall = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_recall\",\n",
    "            recall,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=False,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        self.log(\n",
    "            \"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate F1\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Calculate Precision\n",
    "        metric_precision = BinaryPrecision().to(y.device)\n",
    "        precision = metric_precision(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_precision\",\n",
    "            precision,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        # Calculate Recall\n",
    "        metric_f1 = BinaryRecall().to(y.device)\n",
    "        recall = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_recall\",\n",
    "            recall,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        if isinstance(batch, list):\n",
    "            # Assuming the first element in the list is the input tensor\n",
    "            input_tensor = batch[0]\n",
    "            return self(input_tensor)\n",
    "        else:\n",
    "            # If batch is already a tensor, proceed as usual\n",
    "            print(\"Input Shape:\", batch.shape)\n",
    "            return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.hyperparameters[\"optimizer\"] == \"Adam\":\n",
    "            optimizer = Adam(\n",
    "                self.parameters(), lr=self.hyperparameters[\"lr\"], weight_decay=2e-5\n",
    "            )\n",
    "        elif self.hyperparameters[\"optimizer\"] == \"SGD\":\n",
    "            optimizer = SGD(\n",
    "                self.parameters(), lr=self.hyperparameters[\"lr\"], weight_decay=2e-5\n",
    "            )\n",
    "        elif self.hyperparameters[\"optimizer\"] == \"RMSprop\":\n",
    "            optimizer = RMSprop(\n",
    "                self.parameters(), lr=self.hyperparameters[\"lr\"], weight_decay=2e-5\n",
    "            )\n",
    "\n",
    "        if self.hyperparameters[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "            scheduler = {\n",
    "                \"scheduler\": ReduceLROnPlateau(\n",
    "                    optimizer, mode=\"min\", factor=0.1, patience=3\n",
    "                ),\n",
    "                \"monitor\": \"val_loss\",\n",
    "            }\n",
    "        elif self.hyperparameters[\"scheduler\"] == \"CosineAnnealingLR\":\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hyperparameters = {\n",
    "        \"optimizer\": trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"]),\n",
    "        \"scheduler\": trial.suggest_categorical(\n",
    "            \"scheduler\", [\"ReduceLROnPlateau\", \"CosineAnnealingLR\"]\n",
    "        ),\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-1),\n",
    "        \"dropout\": trial.suggest_float(\"dropout\", 0.01, 1),\n",
    "    }\n",
    "\n",
    "    model = Resnet_model(hyperparameters)\n",
    "    logger = CSVLogger(\"logs\", name=str(trial.number))\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        max_epochs=50,\n",
    "        callbacks=[EarlyStopping(monitor=\"val_loss\", patience=1)],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(\n",
    "        f\"Trial {trial.number} finished with value: {trial.value} and parameters: {trial.params}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI_ZHuioBaZZ"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    preprocess_train,\n",
    "    preprocess_val,\n",
    "    preprocess_test,\n",
    ") = prepare_data.get_timm_transforms(train_NN.Resnet_model())\n",
    "\n",
    "(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    test_dataloader,\n",
    ") = prepare_data.get_dataloaders(\n",
    "    preprocess_train=preprocess_train,\n",
    "    preprocess_val=preprocess_val,\n",
    "    preprocess_test=preprocess_test,\n",
    ")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1701719188301,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "WFR80rxCRGt7",
    "outputId": "64d662af-eb2a-4133-eb32-2752bb27b634"
   },
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1701719223360,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "SMH7y9ZLRGwv",
    "outputId": "0178750d-9ac0-4f53-94ac-497973f793dd"
   },
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1701719256908,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "wIh2lYtcRGzS",
    "outputId": "d448e0ae-552c-411a-c836-f144c0515288"
   },
   "outputs": [],
   "source": [
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1701719295162,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "nD9Lb12mRG1b",
    "outputId": "da8c8f6f-ea3e-4bf4-f8ad-909bc43249dd"
   },
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1NvPurIvAG-FhiUDynbwQfC86juRedJ73",
     "timestamp": 1701721337593
    },
    {
     "file_id": "1oe2LssF1fb7Z3pRCP_eEHJ31sKeevypj",
     "timestamp": 1701632327520
    },
    {
     "file_id": "1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed",
     "timestamp": 1700942428337
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
