{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9vhq3fcEHwj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from google.colab import drive, files, runtime\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B10ISUtcE4nE"
   },
   "source": [
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaleshIpENkS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install scikit-posthocs\n",
    "!pip install optuna\n",
    "!pip install torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQbyJQmAXznU"
   },
   "outputs": [],
   "source": [
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "import timm\n",
    "import train_NN\n",
    "from lightning.pytorch import loggers, callbacks, tuner, trainer, LightningModule\n",
    "\n",
    "import optuna\n",
    "import torchmetrics\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "!unzip -q \"/content/drive/MyDrive/DeepLCMS/ST001618_Opium_study_LC_MS_500_augmented.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh0cGdllMv8h"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWU7V2tIBhAl"
   },
   "source": [
    "# Getting a tunable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYSJJJz1xqhH"
   },
   "outputs": [],
   "source": [
    "class TunedPretrainedModel(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_model_name,\n",
    "        hyperparameters,\n",
    "        learning_rate,\n",
    "        freeze=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.model = timm.create_model(\n",
    "            pretrained_model_name, pretrained=True, num_classes=1\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        self.accuracy = torchmetrics.classification.BinaryAccuracy()\n",
    "        self.f1 = torchmetrics.classification.BinaryF1Score()\n",
    "        self.precision = torchmetrics.classification.BinaryPrecision()\n",
    "        self.recall = torchmetrics.classification.BinaryRecall()\n",
    "\n",
    "        if freeze:\n",
    "            # Freeze all layers\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            # Get the last layer\n",
    "            last_layer = None\n",
    "            for child in self.model.named_children():\n",
    "                last_layer = child\n",
    "\n",
    "            # Unfreeze the last layer\n",
    "            if last_layer is not None:\n",
    "                for param in last_layer[1].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        loss = self.loss_fn(y_pred_logits, y.float())\n",
    "        return loss, y_pred_logits, y\n",
    "\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        prefix,\n",
    "        loss,\n",
    "        accuracy,\n",
    "        f1,\n",
    "        precision,\n",
    "        recall,\n",
    "    ):\n",
    "        self.log_dict(\n",
    "            {\n",
    "                f\"{prefix}_loss\": loss,\n",
    "                f\"{prefix}_accuracy\": accuracy,\n",
    "                f\"{prefix}_f1\": f1,\n",
    "                f\"{prefix}_precision\": precision,\n",
    "                f\"{prefix}_recall\": recall,\n",
    "            },\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y_pred_logits, y = self.common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(y_pred_logits, y)\n",
    "        f1 = self.f1(y_pred_logits, y)\n",
    "        precision = self.precision(y_pred_logits, y)\n",
    "        recall = self.recall(y_pred_logits, y)\n",
    "\n",
    "        self.log_metrics(\"train\", loss, accuracy, f1, precision, recall)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y_pred_logits, y = self.common_step(batch, batch_idx)\n",
    "        accuracy = self.accuracy(y_pred_logits, y)\n",
    "        f1 = self.f1(y_pred_logits, y)\n",
    "        precision = self.precision(y_pred_logits, y)\n",
    "        recall = self.recall(y_pred_logits, y)\n",
    "\n",
    "        self.log_metrics(\"val\", loss, accuracy, f1, precision, recall)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx):\n",
    "        if isinstance(batch, list):\n",
    "            input_tensor = batch[0]\n",
    "            return self(input_tensor)\n",
    "        else:\n",
    "            print(\"Input Shape:\", batch.shape)\n",
    "            return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = None\n",
    "\n",
    "        if self.hyperparameters[\"optimizer\"] == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=2e-5)\n",
    "        elif self.hyperparameters[\"optimizer\"] == \"AdamW\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(), lr=0.001, weight_decay=2e-5\n",
    "            )\n",
    "        elif self.hyperparameters[\"optimizer\"] == \"Adamax\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.parameters(), lr=0.001, weight_decay=2e-5\n",
    "            )\n",
    "        elif self.hyperparameters[\"optimizer\"] == \"RMSprop\":\n",
    "            optimizer = torch.optim.RMSprop(\n",
    "                self.parameters(), lr=0.001, weight_decay=2e-5\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported optimizer: {self.hyperparameters['optimizer']}\"\n",
    "            )\n",
    "\n",
    "        scheduler = None\n",
    "\n",
    "        if self.hyperparameters[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "            scheduler = {\n",
    "                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer, mode=\"min\", factor=0.1, patience=3\n",
    "                ),\n",
    "                \"interval\": \"epoch\",\n",
    "                \"monitor\": \"val_loss\",\n",
    "            }\n",
    "        elif self.hyperparameters[\"scheduler\"] == \"CosineAnnealingLR\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=50, eta_min=0\n",
    "            )\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hyperparameters = {\n",
    "        \"optimizer\": trial.suggest_categorical(\n",
    "            \"optimizer\", [\"Adam\", \"AdamW\", \"Adamax\", \"RMSprop\"]\n",
    "        ),\n",
    "        \"scheduler\": trial.suggest_categorical(\n",
    "            \"scheduler\", [\"ReduceLROnPlateau\", \"CosineAnnealingLR\"]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    model = TunedPretrainedModel(\n",
    "        hyperparameters=hyperparameters,\n",
    "        pretrained_model_name=\"convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384\",\n",
    "        learning_rate=0.001,\n",
    "    )\n",
    "    logger = loggers.CSVLogger(\"logs\", name=str(trial.number))\n",
    "    trainer_ = trainer.Trainer(\n",
    "        logger=logger,\n",
    "        log_every_n_steps=1,\n",
    "        max_epochs=50,\n",
    "        callbacks=[\n",
    "            callbacks.EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "            optuna.integration.PyTorchLightningPruningCallback(\n",
    "                trial, monitor=\"val_loss\"\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer_.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "    return trainer_.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szts8_Aq86jO"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = \"convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384\"\n",
    "\n",
    "model = train_NN.PretrainedModel(\n",
    "    pretrained_model_name=PRETRAINED_MODEL, learning_rate=0.001\n",
    ")\n",
    "datamodule = prepare_data.LCMSDataModule(\n",
    "    model,\n",
    "    data_dir=Path(\"/content/ST001618_Opium_study_LC_MS_500\"),\n",
    ")\n",
    "model.show_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azyNWW18y5jO"
   },
   "outputs": [],
   "source": [
    "# the total number of possible combinations is 15\n",
    "# based on this : nCr = n! / (r! * (n - r)!)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sE2UYgisObM"
   },
   "outputs": [],
   "source": [
    "with open(\"optuna_params.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(study.best_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"optuna_params.pickle\", \"rb\") as handle:\n",
    "    optuna_params = pickle.load(handle)\n",
    "\n",
    "print(study.best_params == optuna_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rmGeF9cORW0"
   },
   "outputs": [],
   "source": [
    "study_df = study.trials_dataframe().sort_values(by=\"value\")\n",
    "study_df.to_csv(\"optuna_study_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ON6KVEMIIds8"
   },
   "outputs": [],
   "source": [
    "# save the result to Google drive\n",
    "results_df = colab_functions.get_experiment_results()\n",
    "results_df.to_csv(\"pretrained_model_results.csv\", index=False)\n",
    "\n",
    "!cp -r \"/content/pretrained_model_results.csv\" \"/content/drive/MyDrive/train_google_colab\"\n",
    "!cp -r \"/content/optuna_study_df.csv\" \"/content/drive/MyDrive/train_google_colab\"\n",
    "!cp -r \"/content/optuna_params.pickle\" \"/content/drive/MyDrive/train_google_colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMH7y9ZLRGwv"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIh2lYtcRGzS"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nD9Lb12mRG1b"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBRV598rLweo"
   },
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAvN08b5uQZB"
   },
   "outputs": [],
   "source": [
    "optuna_epochs = pd.read_csv(\"df_result_epochs.csv\")\n",
    "optuna_trials = pd.read_csv(\"optuna_study_df.csv\")\n",
    "\n",
    "# merge results_df with optuna_trials so that we have access to the full training\n",
    "# data with all epochs\n",
    "# this is needed since optuna made a decision based on overfitted data\n",
    "\n",
    "df = optuna_epochs.merge(optuna_trials, left_on=\"experiment\", right_on=\"number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubkUof9BNK2f"
   },
   "source": [
    "Optuna originally selected trial #6, which achieved a validation loss of 0.2314. This is because Optuna considers the validation loss of the last epoch before terminating the trial due to overfitting. Therefore, the final conclusion reached by Optuna is based on an already overfitted model. Based on the learning curves logged, we can determine the best conditions and the number of epochs we should train our model for.\n",
    "\n",
    "Here are the best models that are resulted in the maximum metrics except for the validation loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "He11v-olGmAa"
   },
   "outputs": [],
   "source": [
    "df.query(\"variable.str.contains('val')\").sort_values(by=\"value_x\").groupby(\n",
    "    \"variable\"\n",
    ").tail(1).query(\"~variable.str.contains('val_loss')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuFOaz4xJhsu"
   },
   "source": [
    "Here is the model that is resulted in the minimum validation loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvFPoJxrItLJ"
   },
   "outputs": [],
   "source": [
    "df.query(\"variable.str.contains('val')\").sort_values(by=\"value_x\").groupby(\n",
    "    \"variable\"\n",
    ").head(1).query(\"variable.str.contains('val_loss')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYF0dXZdORMV"
   },
   "source": [
    "You can see that trial #6 (Adamax and CosineAnnealingLR) performed the best."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
