{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20215,
     "status": "ok",
     "timestamp": 1701193372651,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "eQbyJQmAXznU",
    "outputId": "2deed1f5-2c12-49b9-dba1-c3e48adc6ade"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import train_NN\n",
    "from google.colab import drive\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33376,
     "status": "ok",
     "timestamp": 1701193406025,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "Q6vwf_fWiC8y"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install lets-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aVhaJSvRKg7"
   },
   "source": [
    "\n",
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 36250,
     "status": "ok",
     "timestamp": 1701193442267,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "r0ALswbQkrlq"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install lets-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17084,
     "status": "ok",
     "timestamp": 1701193459348,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1701193460362,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "!unzip -q experiment.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1701101118342,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "Jh0cGdllMv8h",
    "outputId": "cf578ec4-067d-4d58-af10-d05a681e70b1"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiz0GYrqCojF"
   },
   "source": [
    "# Taking a look at the list of Timm pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cNwQ-zGzDZn"
   },
   "outputs": [],
   "source": [
    "timm_model_db = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/huggingface/pytorch-image-models/main/results/results-imagenet.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701112244862,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "jP8GWeJNzYLF",
    "outputId": "44c8de69-265e-4201-f253-846bf18a5263"
   },
   "outputs": [],
   "source": [
    "# Most common unique architecture families\n",
    "\n",
    "most_common = (\n",
    "    timm_model_db.model.str.split(\"_\", expand=True)[0]\n",
    "    .str.split(\".\", expand=True)[0]\n",
    "    .str.split(\"[0-9]\", regex=True, expand=True)[0]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1701112245716,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "7KTdMgA3-MWP",
    "outputId": "02ada492-5b5c-4392-f37b-b91a1281f1d3"
   },
   "outputs": [],
   "source": [
    "most_common_least_parameters = []\n",
    "\n",
    "for most_common_one in most_common.index:\n",
    "    try:\n",
    "        _ = (\n",
    "            timm_model_db.assign(\n",
    "                param_count=lambda df: df.param_count.str.replace(\",\", \"\").astype(float)\n",
    "            )\n",
    "            .query(\"model.str.contains(@most_common_one) and 10<param_count\")\n",
    "            .sort_values(by=\"param_count\")\n",
    "            .reset_index(drop=True)\n",
    "            .loc[0, [\"model\", \"param_count\"]]\n",
    "            .to_dict()\n",
    "        )\n",
    "        most_common_least_parameters.append(_)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "most_common_least_parameters_df = pd.DataFrame(most_common_least_parameters)\n",
    "most_common_least_parameters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OtPJbjSBY48"
   },
   "source": [
    "# Findings the best architecture families based on the models with least\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwDlLgpEqTS0"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import colab_utils\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from timm import create_model\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "\n",
    "PRETRAINED_MODEL= \"tf_efficientnetv2_b2.in1k\"\n",
    "class ExampleModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(PRETRAINED_MODEL, pretrained=True, num_classes=1)\n",
    "\n",
    "        # Freeze all layers except for the last one\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        number_of_features_in = int(self.model.classifier.in_features)\n",
    "\n",
    "        self.model.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=number_of_features_in,\n",
    "                            out_features=int(number_of_features_in/2), bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=int(number_of_features_in/2),\n",
    "                            out_features=int(number_of_features_in/4), bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=int(number_of_features_in/4),\n",
    "                            out_features=1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        self.log(\n",
    "            \"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        if isinstance(batch, list):\n",
    "            # Assuming the first element in the list is the input tensor\n",
    "            input_tensor = batch[0]\n",
    "            return self(input_tensor)\n",
    "        else:\n",
    "            # If batch is already a tensor, proceed as usual\n",
    "            print(\"Input Shape:\", batch.shape)\n",
    "            return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.001,\n",
    "            weight_decay=2e-5,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=20, eta_min=0\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "example_model = ExampleModel()\n",
    "train_NN.show_architecture(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9mrGzl7vYe9"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#metrics_callback = train_NN.MetricsCallback()\n",
    "logger = CSVLogger(\"logs\", name=str(PRETRAINED_MODEL))\n",
    "\n",
    "#trainer = pl.Trainer(max_epochs=1, callbacks=[metrics_callback], log_every_n_steps=1)\n",
    "trainer = pl.Trainer(max_epochs=15, log_every_n_steps=1, logger=logger)\n",
    "\n",
    "trainer.fit(\n",
    "    model=example_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")\n",
    "\n",
    "results_df = colab_functions.get_experiment_results()\n",
    "results_df.to_csv(\"pretrained_model_results.csv\", index=False)\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1701195830517,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "BTT1tSLQ3oI1",
    "outputId": "036e5a1f-d40f-4d58-c2b7-e041bc29adda"
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"pretrained_model_results - Copy.csv\")\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL9-cKprC9D_"
   },
   "source": [
    "# Findings the best version of tf_efficientnetv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1701101178884,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "2MY-xqwszWIk",
    "outputId": "831acbf2-4000-4e12-c83c-3d09f9aa18c3"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "tf_efficientnetv2_models = timm.list_models(\"tf_efficientnetv2*\", pretrained=True)\n",
    "\n",
    "\n",
    "for pretrained_model in tf_efficientnetv2_models:\n",
    "    try:\n",
    "        temp_model = train_NN.PretrainedModelEvaluator(pretrained_model)\n",
    "\n",
    "        (\n",
    "            preprocess_train,\n",
    "            preprocess_val,\n",
    "            preprocess_test,\n",
    "        ) = prepare_data.get_timm_transforms(temp_model)\n",
    "\n",
    "        (\n",
    "            train_dataloader,\n",
    "            val_dataloader,\n",
    "            test_dataloader,\n",
    "        ) = prepare_data.get_dataloaders(\n",
    "            preprocess_train=preprocess_train,\n",
    "            preprocess_val=preprocess_val,\n",
    "            preprocess_test=preprocess_test,\n",
    "        )\n",
    "\n",
    "        # metrics_callback = train_NN.MetricsCallback()\n",
    "        logger = CSVLogger(\"logs\", name=str(pretrained_model))\n",
    "\n",
    "        # trainer = pl.Trainer(max_epochs=1, callbacks=[metrics_callback], log_every_n_steps=1)\n",
    "        trainer = pl.Trainer(max_epochs=15, log_every_n_steps=1, logger=logger)\n",
    "\n",
    "        trainer.fit(\n",
    "            model=temp_model,\n",
    "            train_dataloaders=train_dataloader,\n",
    "            val_dataloaders=val_dataloader,\n",
    "        )\n",
    "\n",
    "        # Clean up resources\n",
    "        resources_to_delete = [\n",
    "            temp_model,\n",
    "            preprocess_train,\n",
    "            preprocess_val,\n",
    "            preprocess_test,\n",
    "            train_dataloader,\n",
    "            val_dataloader,\n",
    "            test_dataloader,\n",
    "            trainer,\n",
    "        ]\n",
    "\n",
    "        gc.collect()\n",
    "    except RuntimeError as e:\n",
    "        pass\n",
    "\n",
    "results_df = colab_functions.get_experiment_results()\n",
    "results_df.to_csv(\"tf_efficientnetv2_models_results.csv\", index=False)\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1701101217174,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "WDMlz05xiEzb",
    "outputId": "556b7e27-a6a3-4a39-9a47-fff996d9aa26"
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"tf_efficientnetv2_models_results.csv\")\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701101217971,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "iY44UTpUSv80",
    "outputId": "84300d7f-fba0-4aef-e84a-188d80d94fcd"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    results_df.assign(epoch=lambda df: df.epoch.astype(int))\n",
    "    .query(\"epoch == 14\")\n",
    "    .sort_values(by=\"val_f1\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWwj6aDljKoj"
   },
   "source": [
    "# Finding the best learining rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtYiUERZ6Xql"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir='/content/lightning_logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WyPV5aMVmiI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxA62ozBNVNV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAzCg2U0NVP-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAx57OqKNVS2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8h0m8e1NVVe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G66-fikANVYo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjz4qnZHLu_g"
   },
   "source": [
    "# Evaluate the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvS5udQOL7jF"
   },
   "outputs": [],
   "source": [
    "preprocess_test = timm.data.create_transform(**data_cfg, is_training=False)\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    transform=preprocess_test,\n",
    "    target_transform=None,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "predictions = trainer.predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZjkhj5pTvH8"
   },
   "outputs": [],
   "source": [
    "all_labels = torch.tensor(test_dataloader.dataset.targets)\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RugisgJRXGP_"
   },
   "outputs": [],
   "source": [
    "probabilities = torch.sigmoid((torch.cat(predictions, dim=0)))\n",
    "\n",
    "# Threshold probabilities to get binary predictions (0 or 1)\n",
    "threshold = 0.5\n",
    "binary_predictions = (probabilities > threshold).float().view(-1)\n",
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWFQo2erdgUT"
   },
   "outputs": [],
   "source": [
    "acc = (all_labels == binary_predictions).sum().item() / len(all_labels)\n",
    "\n",
    "\n",
    "metric_f1 = BinaryF1Score()\n",
    "f1 = metric_f1(all_labels, binary_predictions)\n",
    "\n",
    "\n",
    "bcm = BinaryConfusionMatrix()\n",
    "bcm(all_labels, binary_predictions)\n",
    "fig_, ax_ = bcm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiHKqAvCfA6B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed",
     "timestamp": 1700942428337
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
