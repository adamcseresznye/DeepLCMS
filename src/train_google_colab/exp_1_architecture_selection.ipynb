{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1855,
     "status": "ok",
     "timestamp": 1701452145370,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "S9vhq3fcEHwj",
    "outputId": "b48c102f-a50f-43b5-8285-51aa3b6faa9e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B10ISUtcE4nE"
   },
   "source": [
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34993,
     "status": "ok",
     "timestamp": 1701448327599,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "EaleshIpENkS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18230,
     "status": "ok",
     "timestamp": 1701448345826,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "eQbyJQmAXznU"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import train_NN\n",
    "from google.colab import drive\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from timm import create_model\n",
    "from torchmetrics.classification import (\n",
    "    BinaryF1Score,\n",
    "    BinaryAUROC,\n",
    "    BinaryRecall,\n",
    "    BinaryPrecision,\n",
    ")\n",
    "from pytorch_lightning.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1701448345826,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1701448409729,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "!unzip -q experiment.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1701445287922,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "Jh0cGdllMv8h",
    "outputId": "1b68bc87-e97e-4047-c1ad-c6728862ebec"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiz0GYrqCojF"
   },
   "source": [
    "# Taking a look at the list of Timm pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1701442379961,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "_cNwQ-zGzDZn"
   },
   "outputs": [],
   "source": [
    "timm_model_db = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/huggingface/pytorch-image-models/main/results/results-imagenet.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1701442379962,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "jP8GWeJNzYLF",
    "outputId": "102c12af-4ff7-4b68-e832-7a201453c07c"
   },
   "outputs": [],
   "source": [
    "# Most common unique architecture families\n",
    "\n",
    "most_common = (\n",
    "    timm_model_db.model.str.split(\"_\", expand=True)[0]\n",
    "    .str.split(\".\", expand=True)[0]\n",
    "    .str.split(\"[0-9]\", regex=True, expand=True)[0]\n",
    "    .value_counts()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(20)\n",
    ")\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1701442379963,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "7KTdMgA3-MWP",
    "outputId": "46630bab-9695-4659-e553-65307219ac55"
   },
   "outputs": [],
   "source": [
    "most_common_least_parameters = []\n",
    "\n",
    "for most_common_one in most_common.index:\n",
    "    try:\n",
    "        _ = (\n",
    "            timm_model_db.assign(\n",
    "                param_count=lambda df: df.param_count.str.replace(\",\", \"\").astype(float)\n",
    "            )\n",
    "            .query(\"model.str.contains(@most_common_one) and 10<param_count\")\n",
    "            .sort_values(by=\"param_count\")\n",
    "            .reset_index(drop=True)\n",
    "            .loc[0, [\"model\", \"param_count\"]]\n",
    "            .to_dict()\n",
    "        )\n",
    "        most_common_least_parameters.append(_)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "most_common_least_parameters_df = pd.DataFrame(most_common_least_parameters)\n",
    "most_common_least_parameters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OtPJbjSBY48"
   },
   "source": [
    "# Findings the best architecture family based on the models with least parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwDlLgpEqTS0"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "PRETRAINED_MODEL= \"resnet14t.c3_in1k\"\n",
    "\n",
    "class ExampleModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(PRETRAINED_MODEL, pretrained=True, num_classes=1)\n",
    "\n",
    "        # Freeze all layers except for the last one\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        number_of_features_in = int(self.model.fc.in_features)\n",
    "\n",
    "        self.model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=number_of_features_in,\n",
    "                            out_features=int(number_of_features_in/2), bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(in_features=int(number_of_features_in/2),\n",
    "                            out_features=int(number_of_features_in/4), bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=int(number_of_features_in/4),\n",
    "                            out_features=1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        self.log(\n",
    "            \"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate F1\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_f1\", f1, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate Precision\n",
    "        metric_precision = BinaryPrecision().to(y.device)\n",
    "        precision = metric_precision(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_precision\", precision, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate Recall\n",
    "        metric_f1 = BinaryRecall().to(y.device)\n",
    "        recall = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"train_recall\", recall, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "        y_pred_logits = self(x).squeeze()\n",
    "        y_pred = torch.sigmoid(y_pred_logits)\n",
    "        loss = loss_fn(y_pred, y.float())\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "        # Calculate metrics\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        acc = (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        self.log(\n",
    "            \"val_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate F1\n",
    "        metric_f1 = BinaryF1Score().to(y.device)\n",
    "        f1 = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate Precision\n",
    "        metric_precision = BinaryPrecision().to(y.device)\n",
    "        precision = metric_precision(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_precision\", precision, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        # Calculate Recall\n",
    "        metric_f1 = BinaryRecall().to(y.device)\n",
    "        recall = metric_f1(y_pred_class, y)\n",
    "        self.log(\n",
    "            \"val_recall\", recall, on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        if isinstance(batch, list):\n",
    "            # Assuming the first element in the list is the input tensor\n",
    "            input_tensor = batch[0]\n",
    "            return self(input_tensor)\n",
    "        else:\n",
    "            # If batch is already a tensor, proceed as usual\n",
    "            print(\"Input Shape:\", batch.shape)\n",
    "            return self(batch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=0.001,\n",
    "            weight_decay=2e-5,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=50, eta_min=0\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "example_model = ExampleModel()\n",
    "train_NN.show_architecture(example_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1701449937792,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "rcaTki7tQIge"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "# Construct dataloaders\n",
    "\n",
    "(\n",
    "preprocess_train,\n",
    "preprocess_val,\n",
    "preprocess_test,\n",
    ") = prepare_data.get_timm_transforms(example_model)\n",
    "\n",
    "(\n",
    "train_dataloader,\n",
    "val_dataloader,\n",
    "test_dataloader,\n",
    ") = prepare_data.get_dataloaders(\n",
    "preprocess_train=preprocess_train,\n",
    "preprocess_val=preprocess_val,\n",
    "preprocess_test=preprocess_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9mrGzl7vYe9"
   },
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=str(PRETRAINED_MODEL))\n",
    "\n",
    "trainer = Trainer(max_epochs=50, log_every_n_steps=1, logger=logger,\n",
    "                     callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")]\n",
    "                  )\n",
    "trainer.fit(\n",
    "    model=example_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    ")\n",
    "\n",
    "results_df = colab_functions.get_experiment_results()\n",
    "results_df.to_csv(\"pretrained_model_results.csv\", index=False)\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701456078972,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "uatc6Ot9fYsR",
    "outputId": "87a91e5b-da9d-4158-90f4-11d5f7c7d4f5"
   },
   "outputs": [],
   "source": [
    "# Filter rows with variable containing 'val'\n",
    "filtered_df = df[df[\"variable\"].str.contains(\"val\")]\n",
    "\n",
    "\n",
    "# Apply aggregation with groupby and calculate max and min values per metric\n",
    "result_df_max = (\n",
    "    filtered_df.groupby([\"variable\", \"experiment\"])\n",
    "    .value.max()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    "    .query('variable != \"val_loss\"')\n",
    "    .pivot(index=\"experiment\", columns=\"variable\", values=\"value\")\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "result_df_min = (\n",
    "    filtered_df.groupby([\"variable\", \"experiment\"])\n",
    "    .value.min()\n",
    "    .to_frame()\n",
    "    .reset_index(drop=False)\n",
    "    .query('variable == \"val_loss\"')\n",
    "    .pivot(index=\"experiment\", columns=\"variable\", values=\"value\")\n",
    "    .round(3)\n",
    ")\n",
    "\n",
    "# concatanate the two dfs\n",
    "pd.concat([result_df_max, result_df_min], axis=\"columns\").sort_values(by=\"val_loss\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed",
     "timestamp": 1700942428337
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
