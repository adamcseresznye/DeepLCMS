{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9vhq3fcEHwj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B10ISUtcE4nE"
   },
   "source": [
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaleshIpENkS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install torchmetrics\n",
    "!pip install torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQbyJQmAXznU"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torchinfo\n",
    "import train_NN\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from timm import create_model\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch import LightningModule\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "!unzip -q \"*.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh0cGdllMv8h"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jza-9oViShwj"
   },
   "source": [
    "# Final training with optimized settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ar6_ZfcxSnfy"
   },
   "outputs": [],
   "source": [
    "model = train_NN.Resnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2nqJbuVS2FU"
   },
   "outputs": [],
   "source": [
    "train_NN.show_architecture(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u66P6JuyTu5u"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    preprocess_train,\n",
    "    preprocess_val,\n",
    "    preprocess_test,\n",
    ") = prepare_data.get_timm_transforms(model)\n",
    "\n",
    "(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    test_dataloader,\n",
    ") = prepare_data.get_dataloaders(\n",
    "    preprocess_train=preprocess_train,\n",
    "    preprocess_val=preprocess_val,\n",
    "    preprocess_test=preprocess_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjWol1PYVVC1"
   },
   "outputs": [],
   "source": [
    "# initialize checkpoints\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "logger = CSVLogger(\"logs\", name=\"final_training\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    callbacks=[early_stop, checkpoint_callback],\n",
    "    log_every_n_steps=1,\n",
    "    logger=logger,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6DfcfEbTVy_"
   },
   "outputs": [],
   "source": [
    "colab_functions.plot_experiment_results(colab_functions.get_experiment_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCfE2cKK-j5h"
   },
   "outputs": [],
   "source": [
    "print(checkpoint_callback.best_model_path)  # prints path to the best model's checkpoint\n",
    "print(checkpoint_callback.best_model_score)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEGaMCHzC6vl"
   },
   "outputs": [],
   "source": [
    "print(checkpoint_callback.best_model_path)  # prints path to the best model's checkpoint\n",
    "print(checkpoint_callback.best_model_score)  # and prints it score\n",
    "\n",
    "best_model = train_NN.Resnet_model.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjz4qnZHLu_g"
   },
   "source": [
    "# Evaluate the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvS5udQOL7jF"
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CpS-IEfpU7U"
   },
   "source": [
    "As you can see our model performs exceptionally good:\n",
    "Accuracy: 0.90 | F1: 0.93 | Precision: 0.86 | Recall: 1.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRtqMjiT0g50"
   },
   "outputs": [],
   "source": [
    "colab_functions.evaluate_predictions(\n",
    "    logits=predictions, test_dataloader=test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qWO3v4bqPj_"
   },
   "source": [
    "# Random predictions\n",
    "\n",
    "As demonstrated below, generating random predictions aligned with the distribution of our test set results in:\n",
    "\n",
    "*   Accuracy of 0.50\n",
    "*   F1 score of 0.59\n",
    "*   Precision of 0.73\n",
    "* Recall of 0.50\n",
    "\n",
    "indicating that our model significantly outperforms random guessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg6p3kdiqFYg"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "RANGE = 1000\n",
    "\n",
    "results = {\"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []}\n",
    "\n",
    "for _ in range(RANGE):\n",
    "    true = np.concatenate([np.zeros(8), np.ones(22)])\n",
    "    predicted = np.random.choice([0, 1], 30)\n",
    "\n",
    "    scores = {\n",
    "        \"Accuracy\": metrics.accuracy_score(true, predicted),\n",
    "        \"Precision\": metrics.precision_score(true, predicted),\n",
    "        \"Recall\": metrics.recall_score(true, predicted),\n",
    "        \"F1\": metrics.f1_score(true, predicted),\n",
    "    }\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        results[key].append(value)\n",
    "\n",
    "mean_results = {key: np.mean(values) for key, values in results.items()}\n",
    "\n",
    "print(\n",
    "    f\"Accuracy: {mean_results['Accuracy']:.2f}, F1: {mean_results['F1']:.2f}, Precision: {mean_results['Precision']:.2f}, Recall: {mean_results['Recall']:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZpOpSlKH0mVs"
   },
   "outputs": [],
   "source": [
    "colab_functions.inspect_predictions(logits=predictions, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJlWgJXMLB5X"
   },
   "source": [
    "# Visualize Spatial importance of features via TorchCam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4mxGVpnQre0"
   },
   "outputs": [],
   "source": [
    "best_model = train_NN.Resnet_model.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIcv7q3EXkYx"
   },
   "outputs": [],
   "source": [
    "colab_functios.plot_activation(\n",
    "    test_dataloader, device=device, model=best_model, save=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed",
     "timestamp": 1700942428337
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
