{"cells":[{"cell_type":"markdown","metadata":{"id":"M7o1Je1x0XQU"},"source":["# Mount drive and append path to PYTONPATH\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9vhq3fcEHwj"},"outputs":[],"source":["import os\n","import sys\n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","sys.path.append(\"/content/drive/MyDrive/DeepLCMS/train_google_colab\")"]},{"cell_type":"markdown","metadata":{"id":"B10ISUtcE4nE"},"source":["# Import and install libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EaleshIpENkS"},"outputs":[],"source":["%%capture\n","!pip install lightning\n","!pip install timm\n","!pip install torchinfo\n","!pip install scikit-posthocs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQbyJQmAXznU"},"outputs":[],"source":["import gc\n","from typing import Optional, Tuple\n","from pathlib import Path\n","\n","import colab_functions\n","import colab_utils\n","import pandas as pd\n","import prepare_data\n","import pytorch_lightning as pl\n","import timm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchinfo\n","import train_NN\n","from google.colab import drive\n","from lightning.pytorch.loggers import CSVLogger\n","from pytorch_lightning import LightningModule\n","from pytorch_lightning.callbacks import Callback, EarlyStopping\n","from pytorch_lightning.trainer.trainer import Trainer\n","from timm import create_model\n","from torchmetrics.classification import (\n","    BinaryAUROC,\n","    BinaryF1Score,\n","    BinaryPrecision,\n","    BinaryRecall,\n",")\n","import seaborn as sns\n","import pandas as pd\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import scikit_posthocs as sp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvVdxwYfiHwl"},"outputs":[],"source":["# Set the CUDA_VISIBLE_DEVICES environment variable\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"markdown","metadata":{"id":"yjCM3Grt0NWP"},"source":["# Unzip data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYo52Rm30Q-k"},"outputs":[],"source":["%%script echo skipping\n","!unzip -q \"*.zip\""]},{"cell_type":"markdown","metadata":{"id":"EqmzdwGyVGvJ"},"source":["# Check if GPU is used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jh0cGdllMv8h"},"outputs":[],"source":["device = colab_functions.get_device()"]},{"cell_type":"markdown","metadata":{"id":"KL9-cKprC9D_"},"source":["# Testing experimental conditions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FMsaPrT3wf5"},"outputs":[],"source":["%%script echo skipping\n","img_paths = [path for path in Path(\"./\").rglob(\"ST001618_Opium_study_LC_MS*\") if path.is_dir()]\n","img_paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MY-xqwszWIk"},"outputs":[],"source":["%%script echo skipping\n","\n","for img_path in img_paths:\n","  for round in range(1,6):\n","      try:\n","          print(f\"Round {round}, working on: {img_path}\")\n","          temp_model = train_NN.Resnet_model()\n","\n","          (\n","              preprocess_train,\n","              preprocess_val,\n","              preprocess_test,\n","          ) = prepare_data.get_timm_transforms(temp_model)\n","\n","          (\n","              train_dataloader,\n","              val_dataloader,\n","              test_dataloader,\n","          ) = prepare_data.get_dataloaders(\n","              train_dir = img_path / \"train\",\n","              val_dir = img_path / \"val\",\n","              test_dir = img_path / \"test\",\n","              preprocess_train=preprocess_train,\n","              preprocess_val=preprocess_val,\n","              preprocess_test=preprocess_test,\n","          )\n","\n","          logger = CSVLogger(\"logs\", name=str(img_path))\n","\n","          trainer = Trainer(\n","              max_epochs=50,\n","              log_every_n_steps=1,\n","              logger=logger,\n","              callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")],\n","          )\n","\n","          trainer.fit(\n","              model=temp_model,\n","              train_dataloaders=train_dataloader,\n","              val_dataloaders=val_dataloader,\n","          )\n","\n","          # Clean up resources\n","          resources_to_delete = [\n","              temp_model,\n","              preprocess_train,\n","              preprocess_val,\n","              preprocess_test,\n","              train_dataloader,\n","              val_dataloader,\n","              test_dataloader,\n","              trainer,\n","          ]\n","\n","          gc.collect()\n","      except RuntimeError or ValueError as e:\n","          pass\n","\n","results_df = colab_functions.get_experiment_results()\n","results_df.to_csv(\"experimental_conditions.csv\", index=True)\n","colab_functions.plot_experiment_results(results_df)"]},{"cell_type":"markdown","metadata":{"id":"PBdTZzjGxc6k"},"source":["# Load saved result from disk\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0HztHpWxKNw"},"outputs":[],"source":["# Load saved result from disk\n","results_df = pd.read_csv(\"experimental_conditions.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DRf6UkcAxitM"},"outputs":[],"source":["# Since we ran 5 expeiments per dataset we have to assign a new column\n","# called replicate to designate which replicate the epochs belong to\n","\n","experiments = []\n","counter = 0\n","for experiment in results_df.epoch:\n","    if experiment == 0:\n","        counter = counter + 1\n","        experiments.append(counter)\n","    else:\n","        experiments.append(counter)\n","\n","results_df_w_experiment = pd.concat(\n","    [results_df, pd.Series(experiments)], axis=1\n",").rename(columns={0: \"replicate\"})\n","results_df_w_experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNjAJU5qyhMf"},"outputs":[],"source":["# extracting the maximum values per replicate (except for the loss values)\n","\n","max_values = (\n","    results_df_w_experiment.groupby([\"variable\", \"replicate\", \"experiment\"])\n","    .value.max()\n","    .to_frame()\n","    .reset_index(drop=False)\n","    .query(\"variable != 'val_loss' | variable != 'train_loss'\")\n","    .drop(columns=\"replicate\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EvQk_zp0ts0"},"outputs":[],"source":["# extracting the minimum values per replicate (loss values only)\n","\n","min_values = (\n","    results_df_w_experiment.groupby([\"variable\", \"replicate\", \"experiment\"])\n","    .value.min()\n","    .to_frame()\n","    .reset_index(drop=False)\n","    .query(\"variable == 'val_loss' | variable == 'train_loss'\")\n","    .drop(columns=\"replicate\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dMemIMdH06sC"},"outputs":[],"source":["experiment_replicates = (\n","    pd.concat([max_values, min_values])\n","    .replace(\n","        {\n","            \"ST001618_Opium_study_LC_MS_500\": \"500 images\",\n","            \"ST001618_Opium_study_LC_MS_1000\": \"1000 images\",\n","            \"ST001618_Opium_study_LC_MS_500_augmented\": \"500 images augmented\",\n","            \"ST001618_Opium_study_LC_MS_1000_augmented\": \"1000 images augmented\",\n","        }\n","    )\n","    .assign(variable=lambda df: df.variable.str.replace(\"_\", \" \").str.title())\n",")\n","experiment_replicates.to_csv(\"experiment_replicates.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLIoeQet1gC0"},"outputs":[],"source":["with sns.plotting_context(\"talk\", font_scale=0.8):\n","    grid = sns.FacetGrid(experiment_replicates, col=\"variable\", col_wrap=5)\n","    grid.map_dataframe(\n","        sns.barplot,\n","        y=\"experiment\",\n","        x=\"value\",\n","        capsize=0.15,\n","    )\n","\n","    grid.set_titles(\n","        row_template=\"{row_name}\", col_template=\"{col_name}\", fontweight=\"bold\", size=16\n","    )\n","    grid.set_axis_labels(\"\", \"\")\n","\n","    # Add labels to each bar\n","    for ax in grid.axes.flatten():\n","        for container in ax.containers:\n","            ax.bar_label(\n","                container,\n","                labels=[f\"{x:.2f}\" for x in container.datavalues],\n","                fontsize=10,\n","                padding=17,\n","            )\n","\n","    plt.tight_layout()\n","\n","    grid.savefig(\"experiment_result.png\")"]},{"cell_type":"markdown","metadata":{"id":"B3EMYuoI-q5l"},"source":["# Testing statistical significance with Dunnâ€™s test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM6LUEg89HC7"},"outputs":[],"source":["results_dict = {}\n","\n","for metric in experiment_replicates.variable.unique():\n","    temp_df = experiment_replicates.query(\"variable == @metric\")\n","    print(metric)\n","    dunn_test_results = sp.posthoc_dunn(\n","        a=temp_df, val_col=\"value\", group_col=\"experiment\", p_adjust=\"fdr_bh\"\n","    )\n","\n","    # Add the results to the dictionary\n","    results_dict[metric] = dunn_test_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBu_ZjkID3mb"},"outputs":[],"source":["(\n","    pd.concat(results_dict)\n","    .loc[lambda df: df.apply(lambda row: any(row < 0.05), axis=1), :]\n","    .assign(sum_value=lambda df: df.sum(axis=1))\n","    .drop_duplicates(subset=\"sum_value\")\n","    .drop(columns=\"sum_value\")\n",")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1oe2LssF1fb7Z3pRCP_eEHJ31sKeevypj","timestamp":1701632327520},{"file_id":"1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed","timestamp":1700942428337}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
