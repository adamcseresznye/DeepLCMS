{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7o1Je1x0XQU"
   },
   "source": [
    "# Mount drive and append path to PYTONPATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2487,
     "status": "ok",
     "timestamp": 1702395616624,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "S9vhq3fcEHwj",
    "outputId": "575ce31d-f3cf-4cbd-a521-e734552cf134"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "sys.path.append(\"/content/drive/MyDrive/DeepLCMS/gpu_modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B10ISUtcE4nE"
   },
   "source": [
    "# Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaleshIpENkS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install lightning\n",
    "!pip install timm\n",
    "!pip install torchinfo\n",
    "!pip install scikit-posthocs\n",
    "!pip install optuna\n",
    "!pip install torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQbyJQmAXznU"
   },
   "outputs": [],
   "source": [
    "import colab_functions\n",
    "import colab_utils\n",
    "import pandas as pd\n",
    "import prepare_data\n",
    "import timm\n",
    "import train_NN\n",
    "from lightning.pytorch import loggers, callbacks, tuner, trainer\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikit_posthocs as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvVdxwYfiHwl"
   },
   "outputs": [],
   "source": [
    "# Set the CUDA_VISIBLE_DEVICES environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCM3Grt0NWP"
   },
   "source": [
    "# Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYo52Rm30Q-k"
   },
   "outputs": [],
   "source": [
    "!unzip -q experiment.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmzdwGyVGvJ"
   },
   "source": [
    "# Check if GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh0cGdllMv8h"
   },
   "outputs": [],
   "source": [
    "device = colab_functions.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL9-cKprC9D_"
   },
   "source": [
    "# Getting the candidate models based on Experiment #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zU6zGXoKuuzq"
   },
   "outputs": [],
   "source": [
    "candidates_df = pd.read_csv(\"exp_2_candidates.csv\")\n",
    "\n",
    "pretrained_models = candidates_df.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4RpaR-3vJ1Y"
   },
   "source": [
    "#Inspect a model and its dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw0M1mj1vL4N"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = \"convnextv2_nano.fcmae_ft_in22k_in1k_384\"\n",
    "\n",
    "model = train_NN.PretrainedModel(\n",
    "    pretrained_model_name=PRETRAINED_MODEL, learning_rate=0.001\n",
    ")\n",
    "datamodule = prepare_data.LCMSDataModule(\n",
    "    model,\n",
    "    data_dir=Path(\"/content/ST001618_Opium_study_LC_MS_500\"),\n",
    ")\n",
    "model.show_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYgsNZw2vfRQ"
   },
   "outputs": [],
   "source": [
    "datamodule.inspect_dataloader(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fytR753ZvhQp"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2MY-xqwszWIk"
   },
   "outputs": [],
   "source": [
    "for model_name in tqdm(pretrained_models):\n",
    "    try:\n",
    "        model = train_NN.PretrainedModel(\n",
    "            pretrained_model_name=model_name, learning_rate=0.001\n",
    "        )\n",
    "        datamodule = prepare_data.LCMSDataModule(\n",
    "            model,\n",
    "            data_dir=Path(\"/content/ST001618_Opium_study_LC_MS_500\"),\n",
    "        )\n",
    "\n",
    "        logger = loggers.CSVLogger(\"logs\", name=str(model_name))\n",
    "\n",
    "        trainer_ = trainer.Trainer(\n",
    "            max_epochs=50,\n",
    "            log_every_n_steps=1,\n",
    "            logger=logger,\n",
    "            precision=\"16-mixed\",\n",
    "            callbacks=[\n",
    "                callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "            ],\n",
    "        )\n",
    "        trainer_.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "        del model, datamodule, trainer_\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"{model_name} could not run because {e}\")\n",
    "\n",
    "results_df = colab_functions.get_experiment_results()\n",
    "results_df.to_csv(\"pretrained_model_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnvoaKpxMli"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNxLGgZVwNU4"
   },
   "outputs": [],
   "source": [
    "# This experiment was divided in two parts, hence the two csv files read_ins\n",
    "results_df = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            pd.read_csv(csv_file)\n",
    "            for csv_file in list(Path.cwd().glob(\"pretrained_model_results*\"))\n",
    "        ],\n",
    "        axis=\"index\",\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .assign(\n",
    "        param_count=lambda df: df.experiment.map(\n",
    "            candidates_df.loc[:, [\"model\", \"param_count\"]]\n",
    "            .set_index(\"model\")\n",
    "            .squeeze()\n",
    "            .to_dict()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaUXvaxjk4_T"
   },
   "outputs": [],
   "source": [
    "# next we take a look at what models achieved the lowest val_losses\n",
    "\n",
    "best_models = (\n",
    "    results_df.pivot(\n",
    "        index=[\"epoch\", \"experiment\", \"param_count\"], columns=\"variable\", values=\"value\"\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"experiment\", \"epoch\"])\n",
    "    .loc[lambda df: df.groupby(\"experiment\")[\"val_loss\"].idxmin()]\n",
    "    .sort_values([\"val_loss\", \"val_f1\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "best_models.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ItrQvAqQ7UA"
   },
   "outputs": [],
   "source": [
    "best_models_melted = (\n",
    "    best_models.assign(\n",
    "        family=lambda df: df.experiment.str.split(\"_\", expand=True)[0]\n",
    "        .str.split(\".\", expand=True)[0]\n",
    "        .str.replace(\"\\d+\", \"\")\n",
    "        .replace({\"convnextv\": \"convnext\", \"densenetblurd\": \"densenet\"})\n",
    "    )\n",
    "    .loc[\n",
    "        :,\n",
    "        [\n",
    "            \"experiment\",\n",
    "            \"param_count\",\n",
    "            \"val_accuracy\",\n",
    "            \"val_f1\",\n",
    "            \"val_loss\",\n",
    "            \"val_precision\",\n",
    "            \"val_recall\",\n",
    "            \"family\",\n",
    "        ],\n",
    "    ]\n",
    "    .melt(\n",
    "        id_vars=[\"experiment\", \"family\", \"param_count\"],\n",
    "        value_vars=[\n",
    "            \"val_accuracy\",\n",
    "            \"val_f1\",\n",
    "            \"val_loss\",\n",
    "            \"val_precision\",\n",
    "            \"val_recall\",\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "best_models_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2RoCa5_HVeVo"
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"talk\", font_scale=0.8):\n",
    "    grid = sns.lmplot(\n",
    "        x=\"param_count\",\n",
    "        y=\"value\",\n",
    "        hue=\"variable\",\n",
    "        col=\"family\",\n",
    "        data=best_models_melted,\n",
    "        height=3,\n",
    "        facet_kws=dict(sharex=False, sharey=True),\n",
    "    )\n",
    "    # Add a main title to the entire FacetGrid\n",
    "    # grid.fig.suptitle(f\"{metric}\", fontweight=\"bold\", size=16, y=1.05)\n",
    "    grid.set_titles(\n",
    "        row_template=\"{row_name}\", col_template=\"{col_name}\", fontweight=\"bold\", size=16\n",
    "    )\n",
    "    grid.savefig(\"summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-UzgujIEAHA"
   },
   "source": [
    "# Evaluating variability of top models from the three families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EfdD12wEFtA"
   },
   "outputs": [],
   "source": [
    "candidate_models = [\n",
    "    \"convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384\",\n",
    "    \"mobileone_s3.apple_in1k\",\n",
    "    \"mobilevitv2_200.cvnets_in22k_ft_in1k_384\",\n",
    "]\n",
    "\n",
    "for model_name in tqdm(candidate_models):\n",
    "    for round in range(1, 6):\n",
    "        print(f\"Round {round}, working on: {model_name}\")\n",
    "        model = PretrainedModel(pretrained_model_name=model_name, learning_rate=0.001)\n",
    "        datamodule = LCMSDataModule(\n",
    "            model,\n",
    "            data_dir=Path(\"/kaggle/input/ST001618_Opium_study_LC_MS_500\"),\n",
    "        )\n",
    "\n",
    "        logger = loggers.CSVLogger(\"logs\", name=str(model_name))\n",
    "\n",
    "        trainer_ = trainer.Trainer(\n",
    "            max_epochs=50,\n",
    "            log_every_n_steps=1,\n",
    "            logger=logger,\n",
    "            precision=\"16-mixed\",\n",
    "            callbacks=[\n",
    "                callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        trainer_.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "        del model, datamodule, trainer_\n",
    "        clear_output(wait=True)\n",
    "\n",
    "results_df = colab_functions.get_experiment_results(direcory=r\"/kaggle/working/logs\")\n",
    "results_df.to_csv(\"top_pretrained_model_results_replicates.csv\", index=False)\n",
    "colab_functions.plot_experiment_results(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBv9CpzfqvR_"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-2WkDIlELAO"
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"/content/top_pretrained_model_results_replicates -v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "executionInfo": {
     "elapsed": 50366,
     "status": "ok",
     "timestamp": 1702368791946,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "A2qEPV0_Efhf",
    "outputId": "a49c82e6-fade-4eb0-c547-8c8205349399"
   },
   "outputs": [],
   "source": [
    "colab_functions.plot_experiment_results(results_df, bbox_to_anchor=(1.25, 0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1702395665601,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "pgqrxp_3OmZ_",
    "outputId": "e9b62da8-f111-461a-c723-cba04c0a36d6"
   },
   "outputs": [],
   "source": [
    "# we will get the minimum and maximum values across the experiments for all variables\n",
    "\n",
    "min_values = (\n",
    "    results_df.groupby([\"exp_nr\", \"experiment\", \"variable\"])\n",
    "    .agg({\"value\": \"min\"})\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"experiment\", \"exp_nr\", \"variable\"])\n",
    "    .query(\"variable.str.contains('val') and variable.str.contains('_loss')\")\n",
    ")\n",
    "\n",
    "max_values = (\n",
    "    results_df.groupby([\"exp_nr\", \"experiment\", \"variable\"])\n",
    "    .agg({\"value\": \"max\"})\n",
    "    .reset_index()\n",
    "    .sort_values(by=[\"experiment\", \"exp_nr\", \"variable\"])\n",
    "    .query(\"variable.str.contains('val') and ~variable.str.contains('_loss')\")\n",
    ")\n",
    "max_values\n",
    "\n",
    "concat_summary = pd.concat([min_values, max_values], axis=0)\n",
    "concat_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 3107,
     "status": "ok",
     "timestamp": 1702395674600,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "vv_KzVtnjuqx",
    "outputId": "8c64f211-ffb2-443d-cb0c-04db88be3089"
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"talk\", font_scale=0.8):\n",
    "    grid = sns.FacetGrid(concat_summary, col=\"variable\", col_wrap=5, sharex=False)\n",
    "    grid.map_dataframe(\n",
    "        sns.barplot,\n",
    "        y=\"experiment\",\n",
    "        x=\"value\",\n",
    "        capsize=0.15,\n",
    "    )\n",
    "\n",
    "    grid.set_titles(\n",
    "        row_template=\"{row_name}\", col_template=\"{col_name}\", fontweight=\"bold\", size=16\n",
    "    )\n",
    "    grid.set_axis_labels(\"\", \"\")\n",
    "\n",
    "    # Add labels to each bar\n",
    "    for ax in grid.axes.flatten():\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(\n",
    "                container,\n",
    "                labels=[f\"{x:.2f}\" for x in container.datavalues],\n",
    "                fontsize=10,\n",
    "                padding=17,\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    grid.savefig(\"experiment_result.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FfS9bxNrfZB"
   },
   "source": [
    "# Testing statistical significance with Dunn’s test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noPCDL1kkgCF"
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for metric in concat_summary.variable.unique():\n",
    "    temp_df = concat_summary.query(\"variable == @metric\")\n",
    "    # print(temp_df)\n",
    "    dunn_test_results = sp.posthoc_dunn(\n",
    "        a=temp_df, val_col=\"value\", group_col=\"experiment\", p_adjust=\"fdr_bh\"\n",
    "    )\n",
    "\n",
    "    # Add the results to the dictionary\n",
    "    results_dict[metric] = dunn_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702395681292,
     "user": {
      "displayName": "Adam Cseresznye",
      "userId": "14068185396312405589"
     },
     "user_tz": -60
    },
    "id": "4tn_UyiLkgEr",
    "outputId": "a504f717-80cb-4f39-c6e8-42b602e63a50"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(results_dict)\n",
    "    .loc[lambda df: df.apply(lambda row: any(row < 0.05), axis=1), :]\n",
    "    .assign(sum_value=lambda df: df.sum(axis=1))\n",
    "    .drop_duplicates(subset=\"sum_value\")\n",
    "    .drop(columns=\"sum_value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0hj00rho_Mu"
   },
   "source": [
    "According to the replication study, convnext_large emerged as the most effective model, surpassing both mobileone and mobilevitv2. Despite exhibiting similar patterns, convnext_large exhibited a statistically significant advantage over mobilevitv2 in validation loss (p = 0.01) and achieved significantly better validation recall (p < 0.05). Among the three models tested, mobileone consistently underperformed its counterparts in all performance metrics, except for validation recall, where it narrowly outperformed mobilevitv2 (p < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn_lMLp6jIfo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FxpkTpMoivSD7nQRkqJsjJ_UhxNTpzed",
     "timestamp": 1700942428337
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
